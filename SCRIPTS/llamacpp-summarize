#!.venv/bin/python3
"""
Description: extract the main article text from an URL or file and summarize it with llama.cpp
Requirements: python3 -m venv ~/.venv && ~/.venv/bin/pip3 install bs4 git+https://github.com/buriy/python-readability@v0.8.1 html2text lxml[html_clean] requests
              llama.cpp server must be running locally at http://127.0.0.1:8033/v1
Usage: usage: llm-summarize [-h] [--sentences SENTENCES_NUMBER] (--url URL | --file FILE)
"""
import sys
import argparse
import json
import requests
from bs4 import BeautifulSoup
from readability import Document
import html2text
from pathlib import Path

def get_content(url):
    """
    Get a HTML page content from a URL.
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; rv:128.0) Gecko/20100101 Firefox/128.0'
    }
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        content = response.text
        return content
    except requests.exceptions.RequestException as error:
        print(f"Error querying URL: {error}")
        return None

def get_content_from_file(filepath):
    """
    Get HTML content from a local file.
    """
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        return content
    except FileNotFoundError:
        print(f"Error: File not found: {filepath}")
        return None
    except Exception as error:
        print(f"Error reading file: {error}")
        return None

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--sentences', dest='sentences_number', type=int, default=8, help='number of sentences for the summary. Set to 0 to disable')

    # Create mutually exclusive group for URL and file inputs
    input_group = parser.add_mutually_exclusive_group(required=True)
    input_group.add_argument('--url', dest='urls', type=str, action='append', help='URL of the article to summarize (can be specified multiple times)')
    input_group.add_argument('--file', dest='files', type=str, action='append', help='path to HTML file to summarize (can be specified multiple times)')

    parser.add_argument('--model', dest='model', type=str, default='llama3.2:3b', help='llama.cpp model to use (default llama3.2:3b)')
    parser.add_argument('--server', dest='server', type=str, default='http://127.0.0.1:8033/v1', help='llama.cpp server URL (default http://127.0.0.1:8033/v1)')
    parser.add_argument('--prompt', dest='prompt', type=str, help='custom prompt, replaces the default summarization prompt (but still asks the LLM to only consider the information from the webpage)')
    parser.add_argument('--print-only', dest='print_only', action='store_true', help='only print the extracted plain text from the HTML, do not perform summarization')
    args = parser.parse_args()

    # Determine which input type to process
    sources = []
    if args.urls:
        sources = [('url', url) for url in args.urls]
    elif args.files:
        sources = [('file', filepath) for filepath in args.files]

    for source_type, source in sources:
        # Get content based on source type
        if source_type == 'url':
            content_html = get_content(source)
            source_display = source
        else:  # file
            content_html = get_content_from_file(source)
            source_display = str(Path(source).resolve())

        if not content_html:
            print(f'error processing source: {source}')
            continue

        raw_html = BeautifulSoup(content_html, 'html.parser')
        title_tag = raw_html.find("title")
        title_string = title_tag.text if title_tag else "Untitled"
        print("---------------------------------------------")
        print("\033[0;36m# " + title_string + "\033[0m\n")
        print("\033[0;36m" + source_display + "\033[0m\n")
        try:
            lang = raw_html.html["lang"]
        except (TypeError, KeyError):
            lang = "undefined"

        try:
            tags = raw_html.find("meta", {"name": "ad:rubriques"}).attrs['content'].split(',') # lemonde.fr
        except AttributeError:
            tags = []
        if tags:
            ignored_tags = ['cyclisme', 'sport']
            if any(tag in ignored_tags for tag in tags):
                print(f"Article matches ignored tag, ignoring")
                continue

        content_html = Document(content_html)
        content_summary = content_html.summary()
        soup = BeautifulSoup(content_summary, 'html.parser')
        text_maker = html2text.HTML2Text()
        text_maker.ignore_links = True
        plain_text = text_maker.handle(str(soup))
        if args.print_only:
            print(plain_text)
            continue
        if not args.prompt:
            if args.sentences_number == 0:
                if lang in ['fr', 'fr-FR']:
                    chat_prompt = f'Résume l\'information, en utilisant uniquement les informations suivantes pour fournir une réponse: {plain_text}'
                else:
                    chat_prompt = f'Summarize the information, use only the information in the following text to provide your answer: {plain_text}'
            else:
                if lang in ['fr', 'fr-FR']:
                    chat_prompt = f'Résume l\'information dans le document suivant, limite ta réponse à {str(args.sentences_number)} phrases. Utilise uniquement les informations dans le document pour fournir une réponse. Voici le document: {plain_text}'
                else:
                    chat_prompt = f'Summarize the information in the following document, limit your answer to {str(args.sentences_number)} sentences. Use only the information in the document to provide your answer. Here is the document: {plain_text}'
        else:
            chat_prompt = f'{args.prompt}. use only the information in the following text to provide your answer: {plain_text}'

        # Make request to llama.cpp server
        try:
            payload = {
                'model': args.model,
                'messages': [
                    {'role': 'system', 'content': 'You are a document summarization assistant. When given a document, you reply with a summary of key information in the document'},
                    {'role': 'user', 'content': chat_prompt}
                ],
                'stream': True
            }
            
            response = requests.post(f"{args.server}/chat/completions", json=payload, stream=True)
            response.raise_for_status()
            
            for line in response.iter_lines():
                if line:
                    line_str = line.decode('utf-8')
                    if line_str.startswith('data: '):
                        data_str = line_str[6:]
                        if data_str.strip() == '[DONE]':
                            break
                        try:
                            data = json.loads(data_str)
                            if 'choices' in data and len(data['choices']) > 0:
                                delta = data['choices'][0].get('delta', {})
                                content = delta.get('content', '')
                                if content:
                                    print(content, end='', flush=True)
                        except json.JSONDecodeError:
                            continue
            print()
            
        except requests.exceptions.RequestException as error:
            print(f"Error communicating with llama.cpp server: {error}")
            continue
